"""
HyperNEAT (Hypercube-based NeuroEvolution of Augmenting Topologies) for ECG Classification
Based on: Stanley et al. (2009) "A Hypercube-Based Encoding for Evolving Large-Scale Neural Networks"

HyperNEAT evolves neural networks using:
1. CPPN (Compositional Pattern Producing Network) to generate network weights
2. Geometric encoding based on node positions in hypercube
3. Regularit and symmetry through indirect encoding
4. Genetic algorithm for evolution

Key features:
- Indirect encoding via CPPN
- Geometric relationships between neurons
- Evolution of network topology and weights
- Scales to large networks efficiently
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import List, Tuple, Dict, Optional
import time
import copy


class CPPN(nn.Module):
    """
    Compositional Pattern Producing Network.
    Maps geometric coordinates to connection weights.
    """
    def __init__(self, input_dim: int = 4, hidden_dim: int = 32, num_layers: int = 3):
        super().__init__()
        
        layers = []
        layers.append(nn.Linear(input_dim, hidden_dim))
        layers.append(nn.Tanh())
        
        for _ in range(num_layers - 2):
            layers.append(nn.Linear(hidden_dim, hidden_dim))
            layers.append(nn.Tanh())
        
        layers.append(nn.Linear(hidden_dim, 1))
        layers.append(nn.Tanh())  # Output in [-1, 1]
        
        self.network = nn.Sequential(*layers)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Args:
            x: (batch, 4) - [x1, y1, x2, y2] coordinates
        Returns:
            weight: (batch, 1) - connection weight
        """
        return self.network(x)
    
    def query_weight(self, x1: float, y1: float, x2: float, y2: float) -> float:
        """Query weight for connection between two positions."""
        coords = torch.tensor([[x1, y1, x2, y2]], dtype=torch.float32)
        with torch.no_grad():
            weight = self.network(coords).item()
        return weight


class SubstrateNetwork(nn.Module):
    """
    Substrate network generated by HyperNEAT.
    Network topology is determined by CPPN.
    """
    def __init__(self, input_size: int, hidden_sizes: List[int], output_size: int, cppn: CPPN):
        super().__init__()
        
        self.input_size = input_size
        self.hidden_sizes = hidden_sizes
        self.output_size = output_size
        self.cppn = cppn
        
        # Define substrate geometry (positions in 2D space)
        self.input_positions = self._create_layer_positions(input_size, y=0.0)
        self.hidden_positions = []
        for i, hidden_size in enumerate(hidden_sizes):
            y = (i + 1) / (len(hidden_sizes) + 1)
            self.hidden_positions.append(self._create_layer_positions(hidden_size, y=y))
        self.output_positions = self._create_layer_positions(output_size, y=1.0)
        
        # Generate weights from CPPN
        self.weights = []
        self.biases = []
        self._generate_weights()
        
    def _create_layer_positions(self, size: int, y: float) -> List[Tuple[float, float]]:
        """Create evenly spaced positions for a layer."""
        positions = []
        for i in range(size):
            x = (i / max(size - 1, 1)) * 2 - 1  # Range [-1, 1]
            positions.append((x, y))
        return positions
    
    def _generate_weights(self):
        """Generate weights using CPPN."""
        all_positions = [self.input_positions] + self.hidden_positions + [self.output_positions]
        
        for i in range(len(all_positions) - 1):
            src_positions = all_positions[i]
            dst_positions = all_positions[i + 1]
            
            # Generate weight matrix
            weight_matrix = np.zeros((len(dst_positions), len(src_positions)))
            
            for dst_idx, (x2, y2) in enumerate(dst_positions):
                for src_idx, (x1, y1) in enumerate(src_positions):
                    weight = self.cppn.query_weight(x1, y1, x2, y2)
                    weight_matrix[dst_idx, src_idx] = weight
            
            self.weights.append(torch.tensor(weight_matrix, dtype=torch.float32))
            self.biases.append(torch.zeros(len(dst_positions), dtype=torch.float32))
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Forward pass through substrate network.
        Args:
            x: (batch, input_size)
        Returns:
            output: (batch, output_size)
        """
        for i, (weight, bias) in enumerate(zip(self.weights, self.biases)):
            weight = weight.to(x.device)
            bias = bias.to(x.device)
            x = F.linear(x, weight, bias)
            if i < len(self.weights) - 1:  # Apply activation except last layer
                x = torch.tanh(x)
        return x


class HyperNEATIndividual:
    """Individual in HyperNEAT population."""
    def __init__(self, input_size: int, hidden_sizes: List[int], output_size: int):
        self.input_size = input_size
        self.hidden_sizes = hidden_sizes
        self.output_size = output_size
        
        # Create CPPN
        self.cppn = CPPN(input_dim=4, hidden_dim=32, num_layers=3)
        
        # Generate substrate network
        self.network = SubstrateNetwork(input_size, hidden_sizes, output_size, self.cppn)
        
        self.fitness = 0.0
        
    def mutate(self, mutation_rate: float = 0.1, mutation_strength: float = 0.5):
        """Mutate CPPN parameters."""
        with torch.no_grad():
            for param in self.cppn.parameters():
                if np.random.random() < mutation_rate:
                    noise = torch.randn_like(param) * mutation_strength
                    param.add_(noise)
        
        # Regenerate substrate network after mutation
        self.network = SubstrateNetwork(self.input_size, self.hidden_sizes, self.output_size, self.cppn)
    
    def copy(self):
        """Create a deep copy of this individual."""
        new_individual = HyperNEATIndividual(self.input_size, self.hidden_sizes, self.output_size)
        new_individual.cppn.load_state_dict(copy.deepcopy(self.cppn.state_dict()))
        new_individual.network = SubstrateNetwork(self.input_size, self.hidden_sizes, self.output_size, new_individual.cppn)
        new_individual.fitness = self.fitness
        return new_individual


class HyperNEATPopulation:
    """HyperNEAT evolutionary population."""
    def __init__(
        self,
        input_size: int,
        hidden_sizes: List[int],
        output_size: int,
        population_size: int = 50,
        mutation_rate: float = 0.1,
        mutation_strength: float = 0.5,
        elitism: int = 2
    ):
        self.input_size = input_size
        self.hidden_sizes = hidden_sizes
        self.output_size = output_size
        self.population_size = population_size
        self.mutation_rate = mutation_rate
        self.mutation_strength = mutation_strength
        self.elitism = elitism
        
        # Initialize population
        self.population = [
            HyperNEATIndividual(input_size, hidden_sizes, output_size)
            for _ in range(population_size)
        ]
        
        self.generation = 0
        self.best_individual = None
        self.best_fitness = -np.inf
        
    def evaluate_individual(self, individual: HyperNEATIndividual, X: torch.Tensor, y: torch.Tensor) -> float:
        """Evaluate fitness of an individual."""
        individual.network.eval()
        
        with torch.no_grad():
            outputs = individual.network(X)
            predictions = torch.argmax(outputs, dim=1)
            accuracy = (predictions == y).float().mean().item()
        
        return accuracy
    
    def evaluate_population(self, X: torch.Tensor, y: torch.Tensor):
        """Evaluate fitness of entire population."""
        for individual in self.population:
            individual.fitness = self.evaluate_individual(individual, X, y)
        
        # Update best individual
        for individual in self.population:
            if individual.fitness > self.best_fitness:
                self.best_fitness = individual.fitness
                self.best_individual = individual.copy()
    
    def selection(self) -> List[HyperNEATIndividual]:
        """Tournament selection."""
        selected = []
        tournament_size = 3
        
        for _ in range(self.population_size - self.elitism):
            tournament = np.random.choice(self.population, size=tournament_size, replace=False)
            winner = max(tournament, key=lambda ind: ind.fitness)
            selected.append(winner.copy())
        
        return selected
    
    def evolve(self, X: torch.Tensor, y: torch.Tensor):
        """Evolve population for one generation."""
        # Evaluate current population
        self.evaluate_population(X, y)
        
        # Sort by fitness
        self.population.sort(key=lambda ind: ind.fitness, reverse=True)
        
        # Elitism: keep best individuals
        new_population = [ind.copy() for ind in self.population[:self.elitism]]
        
        # Selection and mutation
        selected = self.selection()
        for individual in selected:
            individual.mutate(self.mutation_rate, self.mutation_strength)
            new_population.append(individual)
        
        self.population = new_population
        self.generation += 1
        
        # Print progress
        avg_fitness = np.mean([ind.fitness for ind in self.population])
        print(f"Generation {self.generation}: Best Fitness = {self.best_fitness:.4f}, Avg Fitness = {avg_fitness:.4f}")


class HyperNEATECG:
    """
    HyperNEAT wrapper for ECG classification.
    """
    def __init__(
        self,
        input_size: int,
        hidden_sizes: List[int] = [64, 32],
        output_size: int = 5,
        population_size: int = 50,
        generations: int = 100,
        mutation_rate: float = 0.1
    ):
        self.input_size = input_size
        self.hidden_sizes = hidden_sizes
        self.output_size = output_size
        self.generations = generations
        
        self.population = HyperNEATPopulation(
            input_size, hidden_sizes, output_size,
            population_size=population_size,
            mutation_rate=mutation_rate
        )
        
    def fit(self, X_train: np.ndarray, y_train: np.ndarray):
        """Train using evolution."""
        X_train_t = torch.FloatTensor(X_train)
        y_train_t = torch.LongTensor(y_train)
        
        print(f"Evolving HyperNEAT for {self.generations} generations...")
        
        for gen in range(self.generations):
            self.population.evolve(X_train_t, y_train_t)
        
        print(f"\nEvolution complete! Best fitness: {self.population.best_fitness:.4f}")
        
    def predict(self, X: np.ndarray) -> np.ndarray:
        """Predict using best individual."""
        X_t = torch.FloatTensor(X)
        
        with torch.no_grad():
            outputs = self.population.best_individual.network(X_t)
            predictions = torch.argmax(outputs, dim=1).numpy()
        
        return predictions
    
    def score(self, X: np.ndarray, y: np.ndarray) -> float:
        """Compute accuracy."""
        predictions = self.predict(X)
        accuracy = np.mean(predictions == y)
        return accuracy


def extract_ecg_features(X: np.ndarray) -> np.ndarray:
    """Extract statistical features from ECG signals."""
    features = []
    
    for signal in X:
        # Time domain features
        mean_val = np.mean(signal)
        std_val = np.std(signal)
        max_val = np.max(signal)
        min_val = np.min(signal)
        
        # Frequency domain features (simple FFT)
        fft = np.fft.fft(signal)
        fft_mag = np.abs(fft[:len(fft)//2])
        dominant_freq_idx = np.argmax(fft_mag)
        dominant_freq = dominant_freq_idx / len(signal)
        
        # Peak detection (simple)
        peaks = np.sum(np.diff(np.sign(np.diff(signal))) < 0)
        
        feature_vector = [
            mean_val, std_val, max_val, min_val,
            dominant_freq, peaks / len(signal),
            np.percentile(signal, 25), np.percentile(signal, 75)
        ]
        
        features.append(feature_vector)
    
    return np.array(features)


def generate_synthetic_ecg(n_samples: int = 500, seq_length: int = 1000, 
                          num_classes: int = 5) -> Tuple[np.ndarray, np.ndarray]:
    """Generate synthetic ECG data."""
    X = []
    y = []
    
    for _ in range(n_samples):
        class_label = np.random.randint(0, num_classes)
        t = np.linspace(0, 4 * np.pi, seq_length)
        
        if class_label == 0:
            signal = np.sin(t) + 0.3 * np.sin(3 * t)
        elif class_label == 1:
            signal = np.sin(t * 1.5) + 0.2 * np.sin(4 * t)
        elif class_label == 2:
            signal = np.sin(t * 2) + 0.2 * np.sin(5 * t)
        elif class_label == 3:
            signal = np.sin(t * 0.5) + 0.3 * np.sin(2 * t)
        else:
            signal = np.sin(t) * np.exp(-t / 10)
        
        signal += 0.1 * np.random.randn(seq_length)
        signal = (signal - signal.mean()) / (signal.std() + 1e-8)
        
        X.append(signal)
        y.append(class_label)
    
    return np.array(X), np.array(y)


if __name__ == "__main__":
    print("=" * 80)
    print("HyperNEAT for ECG Classification")
    print("=" * 80)
    
    np.random.seed(42)
    torch.manual_seed(42)
    
    # Generate data
    print("\nGenerating synthetic ECG data...")
    X, y = generate_synthetic_ecg(n_samples=500, seq_length=1000, num_classes=5)
    
    # Extract features
    print("Extracting features...")
    X_features = extract_ecg_features(X)
    
    # Normalize features
    X_features = (X_features - X_features.mean(axis=0)) / (X_features.std(axis=0) + 1e-8)
    
    # Split data
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)
    
    print(f"Train set: {X_train.shape[0]} samples")
    print(f"Test set: {X_test.shape[0]} samples")
    print(f"Feature dimension: {X_train.shape[1]}")
    
    # Initialize HyperNEAT
    print("\nInitializing HyperNEAT...")
    model = HyperNEATECG(
        input_size=X_train.shape[1],
        hidden_sizes=[16, 8],
        output_size=5,
        population_size=30,
        generations=50,  # Reduced for demo
        mutation_rate=0.15
    )
    
    # Train (evolve)
    print("\nTraining HyperNEAT...")
    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time
    
    # Evaluate
    print("\nEvaluating...")
    train_accuracy = model.score(X_train, y_train) * 100
    test_accuracy = model.score(X_test, y_test) * 100
    
    print("\n" + "=" * 80)
    print("RESULTS")
    print("=" * 80)
    print(f"Training time: {training_time:.2f} seconds")
    print(f"Train accuracy: {train_accuracy:.2f}%")
    print(f"Test accuracy: {test_accuracy:.2f}%")
    print(f"Generations: {model.generations}")
    print(f"Population size: {model.population.population_size}")
    print("=" * 80)
